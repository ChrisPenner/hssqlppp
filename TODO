Syntax support missing
(turn this into a table at some point)
some sql to do:
updates to existing parsers:
select: all, distinct on, having, window
  order by using
  for update/share
delete from
update using

new? parsers

create or replace
alter table
transactions: begin, checkpoint, commit, end, rollback
cursors: declare, open, fetch, move, close, where current of
copy - parse properly
create database
create index
create rule
create trigger + plpgsql support
grant,revoke
listen, notify, unlisten
prepare, execute
savepoint, release savepoint, rollback to savepoint
set, reset
set constraints
set role
set transaction

plpgsql

blocks which aren't at the top level of a function
% types
strict on intos
not null for var defs
exception
execute using
get diagnostics
return query execute
raise missing bits
out params
elsif
loop
exit
labels
reverse, by in for
for in execute

expressions:
process string escapes, support dollar quoting and other quoting more
   robustly in the pretty printer
full user operator support
fix expression parser properly to handle things like between - see
   grammar in pg source for info on how to do this
[:] array slices
aggregate: all and distinct
multi dimensional arrays: selectors and subscripting
isnull, notnull, is [ not ] distinct from, is unknown, is not unknown
basic ops: |/ ||/ ! !! $ | # ~ << >>
substring regex variants
position(in), trim(both from), overlay
like, ilike, ~~ , etc.
similar to
matches: ~ ~* !~ !~*
datetime extract
time zone
geometric, text search, array operators <- should be covered by user
   operator stuff
subquery operators: any, some, all
in general, parsing operators is wrong, the lexer needs to be able to
   lex sequences of symbols into single/multiple operators correctly,
   what happens at the moment is a kludge, also, general operator
   parsing will change how operators are represented in the ast

other ideas (some of this stuff is ridiculously ambitious):

add a exe to help checking the parse/pretty print round trip
using postgresl - take a sql script, parse and pretty print it to a
   separate file, then load the original and the pretty printed into
   empty databases, check no errors, then to a pg dump of each to two
   files then you can eyeball a diff to see how similar they
   look. Probably will have to do some work on cutting down the amount
   of parentheses that the pretty printer produces to make the diffs
   useful for complicated views and functions.

work on error reporting, add tests for malformed sql

fix up expression parser to support full range of pg operators and
   syntax with proper precedence

put code in a well named module

add switch to support other sql dialects in the future - is switch the
   right way? think probably have a completely separate parser, tree
   nodes and pretty printer for each dialect, use cut and paste to get
   started, then see if any commonality can be refactored back in. How
   can a program use the library and write routines to work with
   multiple dialects if the tree nodes are completely separate though?

add token location info to ast nodes, modify for type checking, etc
   support.

add support for passes over this tree to find additional errors which
   the initial parsing misses

add type checking, etc. over the ast.

add a macro system for custom syntax and code generation, etc. - do
   this by providing hooks rather than compromising the vanilla pgsql
   parser. See extension_system for notes on this.

want to report multiple errors, perhaps can bodge this because of the
   property that ';' can only appear inside a string or comment, or
   otherwise at the end of a statement, so add some code to jump
   to the next end of statement looking ';' and continue to parse
   to end of file in an attempt to catch at least some further syntax
   errors

improve tests:
identify each bit of syntax and make sure there is a test for it
add some bigger tests: lots of sql statements, big functions
look for possible corner cases and add tests

get property checker working again - one problem is that the pretty
   printer will reject some asts (which the parser cannot
   produce), and the parser will probably reject some invalid sql that
   the pretty printer will happily produce from some asts.

use the type inferencer:
take a relational valued expression (select, function returning table
   or setof, etc) plus one of:
  sql source of database
  text description of database read using script which reads catalog
  database connection info to read catalog live
and get the type of the relational valued expression
2) - generate a typesafe wrapper to get the value of this expression
   from haskell (see MetaHDBC, if can get this working, will remove
   the need for metahdbc to use odbc to get try and get the type of a
   select statement, although it may still need to access the database
   to read the catalogs e.g. to get the types of tables, functions and
   views).

   Another thing mentioned in connection to MetaHDBC is something that
   is called singleton results in the thread at
   http://lindstroem.wordpress.com/2008/09/18/metahdbc-paper-draft/
   which is the ability to use type inference to determine that the
   value of an relation valued expression contains exactly one
   tuple. Darwen et al.s' (punctuation?) approach

   I'm particularly keen on being able to definitively say whether a
   given column in a relation valued expression can or can't be
   null. (Something I noticed the otherwise pretty good type
   inferencer in ms sql server 2005 was a bit crap at.)

Mads LindstrÃ¸m makes an excellent argument on the above thread for a
   pragmatic approach to accessing sql databases from Haskell,
   avoiding dsls and the like. Supporting such an approach using this
   parser to do type inference on regular sql code for use within
   MetaHDBC and similar systems should be a major goal for this
   library, separate from my megalomaniac ideas about extension
   languages and stuff, and probably a higher priority too.

plpgsql on 'roids:
write libraries in haskell, and then write syntax extensions for
   plpgsql using the extension mechanism to access these libs from
   extended plpgsql e.g. ui lib written in haskell, accessed by syntax
   extensions in plpgsql then can write the database and ui all in the
   same source code in the same language, with first class support for
   properly typed relation valued expressions, avoiding multiple
   languages and mapping/'impedance mismatch' between database types
   and types in the language you write the ui in.
